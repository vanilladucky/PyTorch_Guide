{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport torch\nimport torchtext\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchinfo\nimport time\n\nfrom tqdm import tqdm\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\") \nelse:\n    device = torch.device(\"cpu\")\ndevice","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-03-20T10:00:57.997647Z","iopub.execute_input":"2023-03-20T10:00:57.998044Z","iopub.status.idle":"2023-03-20T10:00:58.010789Z","shell.execute_reply.started":"2023-03-20T10:00:57.998010Z","shell.execute_reply":"2023-03-20T10:00:58.009170Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"#### In this notebook, I will be performing text classifcation using PyTorch. \n#### I hope this can be a good start to learn some basic NLP techniques.","metadata":{}},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\nsample = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\n\ntrain_df, val_df = train_test_split(train, test_size=0.2, random_state=42)\n\ntrain_df = train_df.drop([\"keyword\", \"location\"], axis=1)\nval_df = val_df.drop([\"keyword\", \"location\"], axis=1)\ntest_df = test.drop([\"keyword\", \"location\"], axis=1)\n\ntest_df['target'] = 0 # For the custom dataset later on","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:24:19.013254Z","iopub.execute_input":"2023-03-20T10:24:19.014643Z","iopub.status.idle":"2023-03-20T10:24:19.062641Z","shell.execute_reply.started":"2023-03-20T10:24:19.014595Z","shell.execute_reply":"2023-03-20T10:24:19.061448Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"display(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T09:41:52.370518Z","iopub.execute_input":"2023-03-20T09:41:52.371277Z","iopub.status.idle":"2023-03-20T09:41:52.398909Z","shell.execute_reply.started":"2023-03-20T09:41:52.371241Z","shell.execute_reply":"2023-03-20T09:41:52.397562Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"         id                                               text  target\n4996   7128  Courageous and honest analysis of need to use ...       1\n3263   4688  @ZachZaidman @670TheScore wld b a shame if tha...       0\n4907   6984  Tell @BarackObama to rescind medals of 'honor'...       1\n2855   4103  Worried about how the CA drought might affect ...       1\n4716   6706  @YoungHeroesID Lava Blast &amp; Power Red #Pan...       0\n...     ...                                                ...     ...\n5226   7470  @Eganator2000 There aren't many Obliteration s...       0\n5390   7691  just had a panic attack bc I don't have enough...       0\n860    1242  Omron HEM-712C Automatic Blood Pressure Monito...       0\n7603  10862  Officials say a quarantine is in place at an A...       1\n7270  10409  I moved to England five years ago today. What ...       1\n\n[6090 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4996</th>\n      <td>7128</td>\n      <td>Courageous and honest analysis of need to use ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3263</th>\n      <td>4688</td>\n      <td>@ZachZaidman @670TheScore wld b a shame if tha...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4907</th>\n      <td>6984</td>\n      <td>Tell @BarackObama to rescind medals of 'honor'...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2855</th>\n      <td>4103</td>\n      <td>Worried about how the CA drought might affect ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4716</th>\n      <td>6706</td>\n      <td>@YoungHeroesID Lava Blast &amp;amp; Power Red #Pan...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5226</th>\n      <td>7470</td>\n      <td>@Eganator2000 There aren't many Obliteration s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5390</th>\n      <td>7691</td>\n      <td>just had a panic attack bc I don't have enough...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>1242</td>\n      <td>Omron HEM-712C Automatic Blood Pressure Monito...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7603</th>\n      <td>10862</td>\n      <td>Officials say a quarantine is in place at an A...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7270</th>\n      <td>10409</td>\n      <td>I moved to England five years ago today. What ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>6090 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### The whole point of this exercise is to categorize the type of the text.\n#### If the text is about a real disaster, it is labelled as 1.\n#### If not, it is labelled as 0.","metadata":{}},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-20T09:41:52.400369Z","iopub.execute_input":"2023-03-20T09:41:52.401559Z","iopub.status.idle":"2023-03-20T09:41:52.408856Z","shell.execute_reply.started":"2023-03-20T09:41:52.401505Z","shell.execute_reply":"2023-03-20T09:41:52.407620Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(6090, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### We have 6090 total number of training data.","metadata":{}},{"cell_type":"markdown","source":"## Custom Dataset","metadata":{}},{"cell_type":"markdown","source":"#### Let's create a custom dataset.","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe):\n        self.df = dataframe        \n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, idx):\n        \n        X = self.df['text'].iloc[idx]\n        y = torch.tensor(self.df['target'].iloc[idx], dtype=torch.float)\n            \n        return y, X","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:24:24.773256Z","iopub.execute_input":"2023-03-20T10:24:24.773939Z","iopub.status.idle":"2023-03-20T10:24:24.780817Z","shell.execute_reply.started":"2023-03-20T10:24:24.773895Z","shell.execute_reply":"2023-03-20T10:24:24.779756Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"tokenizer = get_tokenizer('basic_english')\n\nvocab_list = []\nfor row in tqdm(range(train_df.shape[0])):\n    vocab_list.append(tokenizer(train_df['text'].iloc[row]))\n    \nvocab = build_vocab_from_iterator(vocab_list, specials=[\"<unk>\"])\nvocab.set_default_index(vocab[\"<unk>\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:24:24.949167Z","iopub.execute_input":"2023-03-20T10:24:24.950219Z","iopub.status.idle":"2023-03-20T10:24:25.309507Z","shell.execute_reply.started":"2023-03-20T10:24:24.950175Z","shell.execute_reply":"2023-03-20T10:24:25.308230Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stderr","text":"100%|██████████| 6090/6090 [00:00<00:00, 37184.09it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab(['here', 'is', 'an', 'example'])","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:24:25.311671Z","iopub.execute_input":"2023-03-20T10:24:25.312115Z","iopub.status.idle":"2023-03-20T10:24:25.320481Z","shell.execute_reply.started":"2023-03-20T10:24:25.312078Z","shell.execute_reply":"2023-03-20T10:24:25.319041Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"[126, 14, 55, 3380]"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Working as intended!","metadata":{}},{"cell_type":"code","source":"text_pipeline = lambda x: vocab(tokenizer(x))\nlabel_pipeline = lambda x: int(x) ","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:24:25.621290Z","iopub.execute_input":"2023-03-20T10:24:25.621765Z","iopub.status.idle":"2023-03-20T10:24:25.627593Z","shell.execute_reply.started":"2023-03-20T10:24:25.621723Z","shell.execute_reply":"2023-03-20T10:24:25.626254Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"## Custom DataLoader","metadata":{}},{"cell_type":"code","source":"train_dataset_custom = CustomDataset(train_df)\nval_dataset_custom = CustomDataset(val_df)\ntest_dataset_custom = CustomDataset(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:24:26.208803Z","iopub.execute_input":"2023-03-20T10:24:26.209220Z","iopub.status.idle":"2023-03-20T10:24:26.215063Z","shell.execute_reply.started":"2023-03-20T10:24:26.209184Z","shell.execute_reply":"2023-03-20T10:24:26.213766Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"def collate_batch(batch):\n    label_list, text_list, offsets = [], [], [0]\n    for (_label, _text) in batch:\n        label_list.append(label_pipeline(_label))\n        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n        text_list.append(processed_text)\n        offsets.append(processed_text.size(0))\n    label_list = torch.tensor(label_list, dtype=torch.int64)\n    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n    text_list = torch.cat(text_list)\n    return label_list.to(device), text_list.to(device), offsets.to(device)\n\ntrain_dataloader = DataLoader(train_dataset_custom, batch_size=8, shuffle=True, collate_fn=collate_batch)\nval_dataloader = DataLoader(val_dataset_custom, batch_size=8, shuffle=False, collate_fn=collate_batch)\ntest_dataloader = DataLoader(test_dataset_custom, batch_size=1, shuffle=False, collate_fn=collate_batch)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:25:42.175279Z","iopub.execute_input":"2023-03-20T10:25:42.175756Z","iopub.status.idle":"2023-03-20T10:25:42.185956Z","shell.execute_reply.started":"2023-03-20T10:25:42.175714Z","shell.execute_reply":"2023-03-20T10:25:42.184707Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"#### Before sending the data to our model, collate_fn function works on a batch of samples generated from DataLoader.\n#### The offset is a tensor of delimiters to represent the beginning index of the individual sequence in the text tensor. \n#### Label is a tensor saving the labels of individual text entries.\n#### Read more about it [here](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html).","metadata":{}},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"class TextClassificationModel(nn.Module):\n\n    def __init__(self, vocab_size, embed_dim, num_class):\n        super(TextClassificationModel, self).__init__()\n        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n        self.fc = nn.Linear(embed_dim, num_class)\n        self.init_weights()\n\n    def init_weights(self):\n        initrange = 0.5\n        self.embedding.weight.data.uniform_(-initrange, initrange)\n        self.fc.weight.data.uniform_(-initrange, initrange)\n        self.fc.bias.data.zero_()\n\n    def forward(self, text, offsets):\n        embedded = self.embedding(text, offsets)\n        return self.fc(embedded)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:24:36.306022Z","iopub.execute_input":"2023-03-20T10:24:36.306463Z","iopub.status.idle":"2023-03-20T10:24:36.315471Z","shell.execute_reply.started":"2023-03-20T10:24:36.306420Z","shell.execute_reply":"2023-03-20T10:24:36.314217Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"num_class = 2\nvocab_size = len(vocab)\nemsize = 64\nmodel = TextClassificationModel(vocab_size, emsize, num_class).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:24:40.295608Z","iopub.execute_input":"2023-03-20T10:24:40.295985Z","iopub.status.idle":"2023-03-20T10:24:40.324282Z","shell.execute_reply.started":"2023-03-20T10:24:40.295952Z","shell.execute_reply":"2023-03-20T10:24:40.322993Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"def train(dataloader):\n    model.train()\n    total_acc, total_count = 0, 0\n    log_interval = 500\n    start_time = time.time()\n\n    for idx, (label, text, offsets) in enumerate(dataloader):\n        optimizer.zero_grad()\n        predicted_label = model(text, offsets)\n        loss = criterion(predicted_label, label)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optimizer.step()\n        total_acc += (predicted_label.argmax(1) == label).sum().item()\n        total_count += label.size(0)\n        if idx % log_interval == 0 and idx > 0:\n            elapsed = time.time() - start_time\n            print('| epoch {:3d} | {:5d}/{:5d} batches '\n                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n                                              total_acc/total_count))\n            total_acc, total_count = 0, 0\n            start_time = time.time()\n\ndef evaluate(dataloader):\n    model.eval()\n    total_acc, total_count = 0, 0\n\n    with torch.no_grad():\n        for idx, (label, text, offsets) in enumerate(dataloader):\n            predicted_label = model(text, offsets)\n            loss = criterion(predicted_label, label)\n            total_acc += (predicted_label.argmax(1) == label).sum().item()\n            total_count += label.size(0)\n    return total_acc/total_count\n\ndef submission(dataloader): # Code for submission\n    preds = []\n    model.eval()\n    total_acc, total_count = 0, 0\n\n    with torch.no_grad():\n        for idx, (label, text, offsets) in enumerate(dataloader):\n            predicted_label = model(text, offsets)\n            preds.append(predicted_label.argmax(1).item())\n            \n    return preds","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:26:37.958723Z","iopub.execute_input":"2023-03-20T10:26:37.959110Z","iopub.status.idle":"2023-03-20T10:26:37.972655Z","shell.execute_reply.started":"2023-03-20T10:26:37.959077Z","shell.execute_reply":"2023-03-20T10:26:37.971113Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 10\nLR = 5\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\ntotal_accu = None\n\nfor epoch in range(1, EPOCHS + 1):\n    epoch_start_time = time.time()\n    train(train_dataloader)\n    accu_val = evaluate(val_dataloader)\n    if total_accu is not None and total_accu > accu_val:\n        scheduler.step()\n    else:\n        total_accu = accu_val\n    print('-' * 59)\n    print('| end of epoch {:3d} | time: {:5.2f}s | '\n          'valid accuracy {:8.3f} '.format(epoch,\n                                           time.time() - epoch_start_time,\n                                           accu_val))\n    print('-' * 59)\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:24:41.101318Z","iopub.execute_input":"2023-03-20T10:24:41.101725Z","iopub.status.idle":"2023-03-20T10:25:07.812800Z","shell.execute_reply.started":"2023-03-20T10:24:41.101689Z","shell.execute_reply":"2023-03-20T10:25:07.811389Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"| epoch   1 |   500/  762 batches | accuracy    0.653\n-----------------------------------------------------------\n| end of epoch   1 | time:  2.72s | valid accuracy    0.731 \n-----------------------------------------------------------\n\n\n| epoch   2 |   500/  762 batches | accuracy    0.784\n-----------------------------------------------------------\n| end of epoch   2 | time:  2.59s | valid accuracy    0.760 \n-----------------------------------------------------------\n\n\n| epoch   3 |   500/  762 batches | accuracy    0.827\n-----------------------------------------------------------\n| end of epoch   3 | time:  2.78s | valid accuracy    0.787 \n-----------------------------------------------------------\n\n\n| epoch   4 |   500/  762 batches | accuracy    0.861\n-----------------------------------------------------------\n| end of epoch   4 | time:  2.68s | valid accuracy    0.749 \n-----------------------------------------------------------\n\n\n| epoch   5 |   500/  762 batches | accuracy    0.905\n-----------------------------------------------------------\n| end of epoch   5 | time:  2.65s | valid accuracy    0.787 \n-----------------------------------------------------------\n\n\n| epoch   6 |   500/  762 batches | accuracy    0.917\n-----------------------------------------------------------\n| end of epoch   6 | time:  2.51s | valid accuracy    0.791 \n-----------------------------------------------------------\n\n\n| epoch   7 |   500/  762 batches | accuracy    0.924\n-----------------------------------------------------------\n| end of epoch   7 | time:  2.68s | valid accuracy    0.793 \n-----------------------------------------------------------\n\n\n| epoch   8 |   500/  762 batches | accuracy    0.928\n-----------------------------------------------------------\n| end of epoch   8 | time:  2.74s | valid accuracy    0.791 \n-----------------------------------------------------------\n\n\n| epoch   9 |   500/  762 batches | accuracy    0.931\n-----------------------------------------------------------\n| end of epoch   9 | time:  2.66s | valid accuracy    0.789 \n-----------------------------------------------------------\n\n\n| epoch  10 |   500/  762 batches | accuracy    0.932\n-----------------------------------------------------------\n| end of epoch  10 | time:  2.67s | valid accuracy    0.789 \n-----------------------------------------------------------\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"preds = submission(test_dataloader)\n\nsample['target'] = preds\n\nsample.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-20T10:27:23.113594Z","iopub.execute_input":"2023-03-20T10:27:23.114014Z","iopub.status.idle":"2023-03-20T10:27:24.049471Z","shell.execute_reply.started":"2023-03-20T10:27:23.113975Z","shell.execute_reply":"2023-03-20T10:27:24.048485Z"},"trusted":true},"execution_count":115,"outputs":[]}]}