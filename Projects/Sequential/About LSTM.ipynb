{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size:50px;\">About LSTM</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a quick recap on RNN before moving on since LSTM is another improved version of RNN. \n",
    "#### RNN is able to process inputs in a sequential manner.\n",
    "#### Additionally, it has the capability to take into account previous time step's information into its outputs through the presence of hidden states. \n",
    "#### These hidden states are calculated throughout and they are fed in as another input during the next cycle. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size:30px;\">Limitations of LSTMs</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, there are limitations to RNNs.\n",
    "#### The biggest drawback amongst them is the problem of vanishing or exploding gradients. \n",
    "#### The main mechanism to Deep Learning is Backpropagation and this is how models learn. \n",
    "#### However, when the input sequence and learning process gets longer, the model is required to backpropagate longer and peform more matix multiplications due to the chain rule.\n",
    "#### Due to this repetition, small gradients constantly multiplied will result in gradients becoming smaller till they 'vanish' and large gradients constantly multiplied will result in gradients becoming larger till they 'explode'.\n",
    "#### The former will cause models to gradually ignore old information and potentially be unable to train its parameters. \n",
    "#### The latter will cause the model to be extremely unstable during the trainig process.  \n",
    "#### The problem of vanishing gradients is what makes RNN models to suffer from 'short term memory' where they can only take into consideration relatively new information and ignore older ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size:30px;\">What are LSTMs?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With LSTMs, Gating mechanism is introduced to combat the problem of 'short term memory'.\n",
    "#### This mechanism essentially allows LSTM to hold on to contextual information longer and in the case of NLP, this will allow LSTMs to carry out a more humane conversation.\n",
    "#### So how does an LSTM manage this?\n",
    "#### With RNNs, it took in the hidden state and the current sequential input and passed them into a tanh activation function to output an output and a new hidden state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://blog.floydhub.com/content/images/2019/06/Slide18.JPG)<br></br>\n",
    "taken from [website](https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, with LSTMs, it takes in 3 set of information at each time step. \n",
    "#### It takes in the current information, short-term memory (similar to hidden state), and the long-term memory (**cell state**).\n",
    "#### These inputs are then passed through **Gates** which can be seen as filters. \n",
    "#### They decide which information to to be kept and continued forward and which to discard. \n",
    "#### There are 3 gates in total, the input gate, forget gate and the output gate. \n",
    "#### These gates are the ones that are going to be trained to filter out optimally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://blog.floydhub.com/content/images/2019/06/Slide19.JPG)\n",
    "<br></br>\n",
    "taken from [website](https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size:30px;\">Input Gate</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://blog.floydhub.com/content/images/2019/06/Slide20.JPG)\n",
    "<br></br>\n",
    "taken from [website](https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The input gate deals with the current input and the hidden state / short-term memory. \n",
    "#### The **first layer** is the *sigmoid* function. \n",
    "#### This layer transforms both inputs into the range of 0 and 1, 0 being unimportant and 1 being important. \n",
    "#### With backpropagation, this layer will idealy be able to decide which information in the inputs are important and which are not. \n",
    "#### The **second layer** takes both inputs and pass them through the tanh function.\n",
    "#### The outputs from these two layers are then multiplied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size:30px;\">Forget Gate</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://blog.floydhub.com/content/images/2019/06/Slide21.JPG)\n",
    "<br></br>\n",
    "taken from [website](https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This gate decides which information to be kept or discarded from the long-term memory \n",
    "#### This is done by multiplying the incoming long-term memory by a forget vector generated by the current input and incoming short-term memory.\n",
    "#### This forget vector is also a filter.\n",
    "#### It is obtained by passing the current input and hidden state through a sigmoid function, just like in the input gate.\n",
    "#### The output from this forget gate and the output from the input gate, as stated above, undergo a pointwise addition to produce a new version of the long term memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size:30px;\">Ouput Gate</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://blog.floydhub.com/content/images/2019/06/Slide22.JPG)\n",
    "<br></br>\n",
    "taken from [website](https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output gate will take in the new cell state, current input and hidden state to produce the new hidden state (short-term memory) and the output. \n",
    "#### As we can see above, the hidden state and the current input wil be passed into yet another sigmoid function while the new cell state (long-term memory) will be passed into the tanh function.\n",
    "#### The 2 outputs would then be multiplied to produce the new hidden state, short-term memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All of these gates and architecture is what makes up LSTMs!\n",
    "#### It doesn't seem so scary that we broke down the 3 different gates right?\n",
    "#### Let's see what this all looks like in code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size:30px;\">Code Implementation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With PyTorch, all of the above implementation is succintly put into place in the LSTM module.\n",
    "#### All we need to provide is the input dimension, hidden dimension and the number of layers.\n",
    "#### More information can be looked up [here](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "input_dim = 5\n",
    "hidden_dim = 10 \n",
    "n_layers = 2\n",
    "\n",
    "lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True) # batch_first = True for inputs where the batch number comes infront "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So for our dummy input, we would have to create an input with 5 dimensions, so it will have a shape something like this - (1, 1, 5); translates to (batch_size, sequence_length, input dimension)\n",
    "#### We would also have to initialize the hidden state and the cell state to begin the model.\n",
    "#### We will store these two in a tuple format as such: (hidden state, cell state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.4733,  2.9324, -0.9992, -1.3117, -0.4922]]])\n",
      "\n",
      "\n",
      "(tensor([[[ 0.6269, -0.8276,  1.0036, -1.2189, -0.8868, -0.6501,  0.0609,\n",
      "          -0.4498,  0.1131, -0.7280]],\n",
      "\n",
      "        [[ 0.4134, -0.0928, -0.3454, -0.6712,  0.3524, -0.5298, -0.3610,\n",
      "           1.8115, -0.5859, -1.4539]]]), tensor([[[ 1.3978, -1.0708,  0.0432,  0.5728, -1.0821, -0.2057, -1.2685,\n",
      "          -0.5819, -0.5274,  2.8776]],\n",
      "\n",
      "        [[ 0.2657, -1.1280, -2.4326,  1.2444,  1.4502, -1.9727,  1.1661,\n",
      "           0.9338,  0.3324, -0.0380]]]))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 1\n",
    "\n",
    "inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "hidden = (hidden_state, cell_state)\n",
    "\n",
    "print(inp)\n",
    "print(\"\\n\")\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's feed in the input and hidden states to the LSTM layer and see what we get out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([1, 1, 10])\n",
      "Hidden:  (tensor([[[ 0.2829, -0.1436, -0.0019,  0.5156, -0.5277, -0.0451, -0.3547,\n",
      "          -0.2026, -0.2404,  0.5355]],\n",
      "\n",
      "        [[ 0.0401, -0.4179, -0.3990,  0.2737,  0.2545, -0.4048,  0.3471,\n",
      "           0.1079, -0.0328, -0.1444]]], grad_fn=<StackBackward0>), tensor([[[ 0.8280, -0.5253, -0.0040,  0.9147, -0.8501, -0.1955, -0.5973,\n",
      "          -0.8007, -0.9457,  1.3947]],\n",
      "\n",
      "        [[ 0.0735, -0.8427, -1.6736,  0.4338,  1.1018, -1.0239,  0.4952,\n",
      "           0.2497, -0.0474, -0.2649]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "out, hidden = lstm_layer(inp, hidden)\n",
    "print(\"Output shape: \", out.shape)\n",
    "print(\"Hidden: \", hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this scenario, the input only had a sequence length of 1. \n",
    "#### However, in most cases, our input would have a sequence length that is way longer, especially for NLP tasks. \n",
    "#### In that case, we just need to change the sequence length and we would obtain an output with that sequence length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "seq_len = 3\n",
    "inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "out, hidden = lstm_layer(inp, hidden)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see, the output shows a sequence length of 3 after taking in an input of sequence length 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we know how a LSTM layer in PyTorch works, let's put this to practical use. \n",
    "#### We will be utilizing a dataset from Kaggle that contains Amazon reviews that are classified as either positive or negative. \n",
    "#### Let's see what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "path_to_image = os.getenv(\"AMAZON_REVIEWS_PATH\")\n",
    "\n",
    "train_file = bz2.BZ2File(path_to_image + 'train.ft.txt.bz2', \"r\")\n",
    "test_file = bz2.BZ2File(path_to_image + 'test.ft.txt.bz2', \"r\")\n",
    "\n",
    "train_file = train_file.readlines()\n",
    "test_file = test_file.readlines()\n",
    "\n",
    "num_train = 3600000//4  # We're training on the first 800,000 reviews in the dataset\n",
    "num_test = 400000//4  # Using 200,000 reviews from test set\n",
    " \n",
    "train_file = [x.decode('utf-8') for x in train_file[:num_train]]\n",
    "test_file = [x.decode('utf-8') for x in test_file[:num_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The file is in the format of __label__(classification) (sentence).\n",
    "#### Positive sentiment is stored as 2 while negative ones are stored as 1.\n",
    "#### However, we will be changing them to 1 for positive and 0 for negative sentiments. \n",
    "#### In the sentences, there are also URLs written but this is irrelevant in our case, so we will be transforming them to a standard <url\\>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels from sentences\n",
    "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file]\n",
    "train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file]\n",
    "\n",
    "test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file]\n",
    "test_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file]\n",
    "\n",
    "# Some simple cleaning of data\n",
    "for i in range(len(train_sentences)):\n",
    "    train_sentences[i] = re.sub('\\d','0',train_sentences[i])\n",
    "\n",
    "for i in range(len(test_sentences)):\n",
    "    test_sentences[i] = re.sub('\\d','0',test_sentences[i])\n",
    "\n",
    "# Modify URLs to <url>\n",
    "for i in range(len(train_sentences)):\n",
    "    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n",
    "        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])\n",
    "        \n",
    "for i in range(len(test_sentences)):\n",
    "    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n",
    "        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that cleaning is done, we have to perform **tokenization**.\n",
    "#### Tokenization is the act of splitting up a sentence into tokens, be it words or punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900000/900000 [04:15<00:00, 3520.05it/s]\n"
     ]
    }
   ],
   "source": [
    "words = Counter()  # Dictionary that will map a word to the number of times it appeared in all the training sentences\n",
    "for i, sentence in enumerate(tqdm(train_sentences)):\n",
    "    # The sentences will be stored as a list of words/tokens\n",
    "    train_sentences[i] = []\n",
    "    for word in nltk.word_tokenize(sentence):  # Tokenizing the words\n",
    "        words.update([word.lower()])  # Converting all the words to lowercase\n",
    "        train_sentences[i].append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additionally, to remove any unlikely words, we will remove words with occurence of only 1. \n",
    "#### To account for potentially unencountered words or padding, we will add them to our words dictionary too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the words that only appear once\n",
    "words = {k:v for k,v in words.items() if v>1}\n",
    "# Sorting the words according to the number of appearances, with the most common word being first\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "# Adding padding and unknown to our vocabulary so that they will be assigned an index\n",
    "words = ['_PAD','_UNK'] + words\n",
    "# Dictionaries to store the word to index mappings and vice versa\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we got the tokenization and indexing in place, let us apply them to our sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900000/900000 [00:05<00:00, 155450.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(tqdm(train_sentences)):\n",
    "    # Looking up the mapping dictionary and assigning the index to the respective words\n",
    "    train_sentences[i] = [word2idx[word] if word in word2idx else word2idx['_UNK'] for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:27<00:00, 3633.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(tqdm(test_sentences)):\n",
    "    # For test sentences, we have to tokenize the sentences as well\n",
    "    test_sentences[i] = [word2idx[word.lower()] if word.lower() in word2idx else word2idx['_UNK'] for word in nltk.word_tokenize(sentence)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now onto the last preprocessing step. \n",
    "#### We'll be padding the sentences with 0s and shortening the lengthy sentences so that the data can be trained in batches to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that either shortens sentences or pads sentences with 0 to a fixed length\n",
    "def pad_input(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            # Padding will be applied to the front\n",
    "            # If the length of the sentence is shorter than the seq_len, it will be padded with 0s from the start\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len] \n",
    "    return features\n",
    "\n",
    "seq_len = 200  # The length that the sentences will be padded/shortened to\n",
    "\n",
    "train_sentences = pad_input(train_sentences, seq_len)\n",
    "test_sentences = pad_input(test_sentences, seq_len)\n",
    "\n",
    "# Converting our labels into numpy arrays\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see what a padded sentence looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,  66158,     88,     16,      3, 109253,     13,     11,\n",
       "          192,    449,     18,    362,     15,      9,   5806,      3,\n",
       "        96575,     14,     77,    433,     36,     89,      5,     50,\n",
       "         1680,      9,     88,      8,    141,     80,    622,  18971,\n",
       "            2,    186,    124,     15,      5,     27,    537,      3,\n",
       "          186,  18277,   2058,     22,     55,     10,     35,     10,\n",
       "            3,    733,      5,     27,    132,    537,      9,     57,\n",
       "            3,     96,    124,     15,      9,   7353,    262,     48,\n",
       "         4669,  46939,      6,    434,      7,  17883,   1081,     23,\n",
       "         9128,   2702,      6,   3928,  19199,      2,      9,     50,\n",
       "         4852,    207,     80,   2407,      8,    311,     15,  16926])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok so now that's done, let us go ahead and divide our training set into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.5 # 50% validation, 50% test\n",
    "split_id = int(split_frac * len(test_sentences))\n",
    "val_sentences, test_sentences = test_sentences[:split_id], test_sentences[split_id:]\n",
    "val_labels, test_labels = test_labels[:split_id], test_labels[split_id:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now feed in these data into DataLoaders using PyTorch library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_sentences), torch.from_numpy(train_labels))\n",
    "val_data = TensorDataset(torch.from_numpy(val_sentences), torch.from_numpy(val_labels))\n",
    "test_data = TensorDataset(torch.from_numpy(test_sentences), torch.from_numpy(test_labels))\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's set up our device too so that we won't be held back by our CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now onto the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx) + 1\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "model.to(device)\n",
    "\n",
    "lr=0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 99/9000 [00:50<1:18:38,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 100... Loss: 0.486787... Val Loss: 0.502854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/9000 [02:06<56:45:35, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.502854).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 199/9000 [03:12<1:36:47,  1.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 200... Loss: 0.417106... Val Loss: 0.370372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 200/9000 [04:58<78:44:59, 32.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.502854 --> 0.370372).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 299/9000 [06:27<2:04:21,  1.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 300... Loss: 0.295222... Val Loss: 0.294911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 300/9000 [08:10<76:36:17, 31.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.370372 --> 0.294911).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 399/9000 [09:30<1:38:37,  1.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 400... Loss: 0.189338... Val Loss: 0.286997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 400/9000 [11:01<66:31:54, 27.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.294911 --> 0.286997).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 499/9000 [12:13<1:25:44,  1.65it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 500... Loss: 0.331447... Val Loss: 0.253947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 500/9000 [13:33<58:07:17, 24.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.286997 --> 0.253947).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 599/9000 [14:38<1:31:10,  1.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 600... Loss: 0.231808... Val Loss: 0.248325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 600/9000 [15:53<53:34:41, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.253947 --> 0.248325).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 699/9000 [16:54<1:23:48,  1.65it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 700... Loss: 0.240730... Val Loss: 0.239384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 700/9000 [18:12<55:23:18, 24.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.248325 --> 0.239384).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 800/9000 [20:33<54:48:18, 24.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 800... Loss: 0.340206... Val Loss: 0.240664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 900/9000 [22:53<54:16:57, 24.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 900... Loss: 0.271002... Val Loss: 0.245783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 999/9000 [23:59<1:22:42,  1.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1000... Loss: 0.248659... Val Loss: 0.230929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1000/9000 [25:16<52:27:25, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.239384 --> 0.230929).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1100/9000 [27:39<50:19:52, 22.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1100... Loss: 0.217460... Val Loss: 0.244217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1199/9000 [28:42<1:23:51,  1.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1200... Loss: 0.199470... Val Loss: 0.222822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1200/9000 [30:02<53:03:13, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.230929 --> 0.222822).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1299/9000 [31:02<1:17:09,  1.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1300... Loss: 0.187632... Val Loss: 0.222632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1300/9000 [32:23<52:17:48, 24.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.222822 --> 0.222632).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1399/9000 [33:25<1:25:19,  1.48it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1400... Loss: 0.153965... Val Loss: 0.219430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1400/9000 [34:44<51:12:58, 24.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.222632 --> 0.219430).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1499/9000 [35:46<1:20:44,  1.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1500... Loss: 0.189915... Val Loss: 0.214531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1500/9000 [37:04<49:07:47, 23.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.219430 --> 0.214531).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1600/9000 [39:24<48:19:03, 23.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1600... Loss: 0.279372... Val Loss: 0.216673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1700/9000 [41:43<47:55:27, 23.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1700... Loss: 0.163903... Val Loss: 0.217184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1800/9000 [44:00<45:47:52, 22.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1800... Loss: 0.247262... Val Loss: 0.214748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1899/9000 [45:05<1:13:39,  1.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1900... Loss: 0.208919... Val Loss: 0.213868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1900/9000 [46:25<48:15:02, 24.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.214531 --> 0.213868).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1999/9000 [47:29<1:20:29,  1.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 2000... Loss: 0.148321... Val Loss: 0.210958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2000/9000 [48:57<52:09:31, 26.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.213868 --> 0.210958).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2099/9000 [49:59<1:11:10,  1.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 2100... Loss: 0.260450... Val Loss: 0.207000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2100/9000 [51:17<45:31:33, 23.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.210958 --> 0.207000).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2200/9000 [53:39<43:53:48, 23.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 2200... Loss: 0.304374... Val Loss: 0.208405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2300/9000 [55:59<44:28:06, 23.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 2300... Loss: 0.163608... Val Loss: 0.207344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2400/9000 [58:19<42:39:06, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 2400... Loss: 0.241463... Val Loss: 0.208968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2500/9000 [1:01:04<53:36:08, 29.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 2500... Loss: 0.185054... Val Loss: 0.213986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2600/9000 [1:03:32<43:22:39, 24.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 2600... Loss: 0.181295... Val Loss: 0.209748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 2700/9000 [1:06:02<46:21:48, 26.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 2700... Loss: 0.142324... Val Loss: 0.215918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2799/9000 [1:07:22<1:13:41,  1.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 2800... Loss: 0.215754... Val Loss: 0.205298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 2800/9000 [1:08:46<43:52:50, 25.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.207000 --> 0.205298).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2900/9000 [1:11:10<42:25:28, 25.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 2900... Loss: 0.191231... Val Loss: 0.209452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2999/9000 [1:12:17<1:02:24,  1.60it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 3000... Loss: 0.079199... Val Loss: 0.203712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3000/9000 [1:13:52<48:20:45, 29.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.205298 --> 0.203712).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3100/9000 [1:16:58<52:22:17, 31.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 3100... Loss: 0.292360... Val Loss: 0.222340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3199/9000 [1:18:18<1:16:12,  1.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 3200... Loss: 0.170858... Val Loss: 0.199280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3200/9000 [1:19:44<42:39:39, 26.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.203712 --> 0.199280).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3300/9000 [1:22:02<37:45:17, 23.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 3300... Loss: 0.191370... Val Loss: 0.200201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3400/9000 [1:24:48<48:09:02, 30.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 3400... Loss: 0.193973... Val Loss: 0.209092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3500/9000 [1:27:18<39:03:22, 25.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 3500... Loss: 0.227910... Val Loss: 0.211358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 3600/9000 [1:30:15<45:23:17, 30.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 3600... Loss: 0.109052... Val Loss: 0.208596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3700/9000 [1:32:39<34:06:53, 23.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 3700... Loss: 0.197191... Val Loss: 0.206733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3799/9000 [1:33:41<56:50,  1.53it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 3800... Loss: 0.153083... Val Loss: 0.197325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3800/9000 [1:34:57<33:25:40, 23.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.199280 --> 0.197325).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3899/9000 [1:36:00<56:07,  1.51it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 3900... Loss: 0.236235... Val Loss: 0.193792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3900/9000 [1:37:19<34:09:31, 24.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.197325 --> 0.193792).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4000/9000 [1:39:36<31:56:38, 23.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 4000... Loss: 0.272521... Val Loss: 0.195973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4100/9000 [1:41:54<31:42:14, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 4100... Loss: 0.093463... Val Loss: 0.196697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4200/9000 [1:44:12<31:19:41, 23.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 4200... Loss: 0.208734... Val Loss: 0.198449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4300/9000 [1:46:27<30:13:06, 23.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 4300... Loss: 0.236781... Val Loss: 0.197796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4400/9000 [1:48:46<30:46:56, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 4400... Loss: 0.235728... Val Loss: 0.198216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4500/9000 [1:51:04<29:21:07, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 4500... Loss: 0.195045... Val Loss: 0.197779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 4600/9000 [1:53:25<30:04:09, 24.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 4600... Loss: 0.139202... Val Loss: 0.215025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4700/9000 [1:55:55<30:22:48, 25.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 4700... Loss: 0.175416... Val Loss: 0.202637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 4800/9000 [1:58:24<28:08:23, 24.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 4800... Loss: 0.156954... Val Loss: 0.200486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 4901/9000 [2:01:31<30:51:55, 27.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 4900... Loss: 0.185270... Val Loss: 0.198494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5000/9000 [2:04:17<28:17:32, 25.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 5000... Loss: 0.274219... Val Loss: 0.195871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5100/9000 [2:06:47<27:57:36, 25.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 5100... Loss: 0.309938... Val Loss: 0.203488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5200/9000 [2:09:08<24:39:59, 23.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 5200... Loss: 0.288327... Val Loss: 0.198016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5300/9000 [2:11:31<25:21:50, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 5300... Loss: 0.211069... Val Loss: 0.209740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 5400/9000 [2:13:50<23:39:57, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 5400... Loss: 0.171950... Val Loss: 0.199787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 5500/9000 [2:16:07<21:43:00, 22.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 5500... Loss: 0.155911... Val Loss: 0.203747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 5600/9000 [2:18:19<21:07:09, 22.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 5600... Loss: 0.141213... Val Loss: 0.200105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5700/9000 [2:20:32<20:31:20, 22.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 5700... Loss: 0.162184... Val Loss: 0.204469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 5800/9000 [2:22:45<20:01:38, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 5800... Loss: 0.267422... Val Loss: 0.202936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 5888/9000 [2:23:37<30:46,  1.69it/s]   "
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    h = model.init_hidden(batch_size)\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        counter += 1\n",
    "        h = tuple([e.data for e in h])\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in val_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out, val_h = model(inp, val_h)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how well our model has performed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:59<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.192\n",
      "Test accuracy: 92.560%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the best model\n",
    "model.load_state_dict(torch.load('./state_dict.pt'))\n",
    "\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "model.eval()\n",
    "for inputs, labels in tqdm(test_loader):\n",
    "    h = tuple([each.data for each in h])\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    output, h = model(inputs, h)\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    pred = torch.round(output.squeeze())  # Rounds the output to 0/1\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A test accuracy of 92.5%! Impressive! \n",
    "#### I hope we see how impressive a LSTM can be."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('machinelearning': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68339890f90b7cc04351217391b998bebccc50e4c246697aa46d0c3bd6df040a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
