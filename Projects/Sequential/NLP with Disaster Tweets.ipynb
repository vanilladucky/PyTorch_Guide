{"cells":[{"cell_type":"code","execution_count":45,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-20T10:00:57.998044Z","iopub.status.busy":"2023-03-20T10:00:57.997647Z","iopub.status.idle":"2023-03-20T10:00:58.010789Z","shell.execute_reply":"2023-03-20T10:00:58.009170Z","shell.execute_reply.started":"2023-03-20T10:00:57.998010Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd \n","import torch\n","import torchtext\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing import sequence\n","from keras.preprocessing.text import Tokenizer\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchinfo\n","import time\n","\n","from tqdm import tqdm\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\") \n","else:\n","    device = torch.device(\"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{},"source":["# Introduction"]},{"cell_type":"markdown","metadata":{},"source":["#### In this notebook, I will be performing text classifcation using PyTorch. \n","#### I hope this can be a good start to learn some basic NLP techniques."]},{"cell_type":"markdown","metadata":{},"source":["# Data"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:24:19.014643Z","iopub.status.busy":"2023-03-20T10:24:19.013254Z","iopub.status.idle":"2023-03-20T10:24:19.062641Z","shell.execute_reply":"2023-03-20T10:24:19.061448Z","shell.execute_reply.started":"2023-03-20T10:24:19.014595Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n","test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n","sample = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\n","\n","train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)\n","\n","train_df = train_df.drop([\"keyword\", \"location\"], axis=1)\n","val_df = val_df.drop([\"keyword\", \"location\"], axis=1)\n","test_df = test.drop([\"keyword\", \"location\"], axis=1)\n","\n","test_df['target'] = 0 # For the custom dataset later on"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T09:41:52.371277Z","iopub.status.busy":"2023-03-20T09:41:52.370518Z","iopub.status.idle":"2023-03-20T09:41:52.398909Z","shell.execute_reply":"2023-03-20T09:41:52.397562Z","shell.execute_reply.started":"2023-03-20T09:41:52.371241Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4996</th>\n","      <td>7128</td>\n","      <td>Courageous and honest analysis of need to use ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3263</th>\n","      <td>4688</td>\n","      <td>@ZachZaidman @670TheScore wld b a shame if tha...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4907</th>\n","      <td>6984</td>\n","      <td>Tell @BarackObama to rescind medals of 'honor'...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2855</th>\n","      <td>4103</td>\n","      <td>Worried about how the CA drought might affect ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4716</th>\n","      <td>6706</td>\n","      <td>@YoungHeroesID Lava Blast &amp;amp; Power Red #Pan...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5226</th>\n","      <td>7470</td>\n","      <td>@Eganator2000 There aren't many Obliteration s...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5390</th>\n","      <td>7691</td>\n","      <td>just had a panic attack bc I don't have enough...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>860</th>\n","      <td>1242</td>\n","      <td>Omron HEM-712C Automatic Blood Pressure Monito...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7603</th>\n","      <td>10862</td>\n","      <td>Officials say a quarantine is in place at an A...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7270</th>\n","      <td>10409</td>\n","      <td>I moved to England five years ago today. What ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6090 rows × 3 columns</p>\n","</div>"],"text/plain":["         id                                               text  target\n","4996   7128  Courageous and honest analysis of need to use ...       1\n","3263   4688  @ZachZaidman @670TheScore wld b a shame if tha...       0\n","4907   6984  Tell @BarackObama to rescind medals of 'honor'...       1\n","2855   4103  Worried about how the CA drought might affect ...       1\n","4716   6706  @YoungHeroesID Lava Blast &amp; Power Red #Pan...       0\n","...     ...                                                ...     ...\n","5226   7470  @Eganator2000 There aren't many Obliteration s...       0\n","5390   7691  just had a panic attack bc I don't have enough...       0\n","860    1242  Omron HEM-712C Automatic Blood Pressure Monito...       0\n","7603  10862  Officials say a quarantine is in place at an A...       1\n","7270  10409  I moved to England five years ago today. What ...       1\n","\n","[6090 rows x 3 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(train_df)"]},{"cell_type":"markdown","metadata":{},"source":["#### The whole point of this exercise is to categorize the type of the text.\n","#### If the text is about a real disaster, it is labelled as 1.\n","#### If not, it is labelled as 0."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T09:41:52.401559Z","iopub.status.busy":"2023-03-20T09:41:52.400369Z","iopub.status.idle":"2023-03-20T09:41:52.408856Z","shell.execute_reply":"2023-03-20T09:41:52.407620Z","shell.execute_reply.started":"2023-03-20T09:41:52.401505Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(6090, 3)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_df.shape"]},{"cell_type":"markdown","metadata":{},"source":["#### We have 6090 total number of training data."]},{"cell_type":"markdown","metadata":{},"source":["## Custom Dataset"]},{"cell_type":"markdown","metadata":{},"source":["#### Let's create a custom dataset."]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:24:24.773939Z","iopub.status.busy":"2023-03-20T10:24:24.773256Z","iopub.status.idle":"2023-03-20T10:24:24.780817Z","shell.execute_reply":"2023-03-20T10:24:24.779756Z","shell.execute_reply.started":"2023-03-20T10:24:24.773895Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, dataframe):\n","        self.df = dataframe        \n","        \n","    def __len__(self):\n","        return self.df.shape[0]\n","    \n","    def __getitem__(self, idx):\n","        \n","        X = self.df['text'].iloc[idx]\n","        y = torch.tensor(self.df['target'].iloc[idx], dtype=torch.float)\n","            \n","        return y, X"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:24:24.950219Z","iopub.status.busy":"2023-03-20T10:24:24.949167Z","iopub.status.idle":"2023-03-20T10:24:25.309507Z","shell.execute_reply":"2023-03-20T10:24:25.308230Z","shell.execute_reply.started":"2023-03-20T10:24:24.950175Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 6090/6090 [00:00<00:00, 37184.09it/s]\n"]}],"source":["tokenizer = get_tokenizer('basic_english')\n","\n","vocab_list = []\n","for row in tqdm(range(train_df.shape[0])):\n","    vocab_list.append(tokenizer(train_df['text'].iloc[row]))\n","    \n","vocab = build_vocab_from_iterator(vocab_list, specials=[\"<unk>\"])\n","vocab.set_default_index(vocab[\"<unk>\"])"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:24:25.312115Z","iopub.status.busy":"2023-03-20T10:24:25.311671Z","iopub.status.idle":"2023-03-20T10:24:25.320481Z","shell.execute_reply":"2023-03-20T10:24:25.319041Z","shell.execute_reply.started":"2023-03-20T10:24:25.312078Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[126, 14, 55, 3380]"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["vocab(['here', 'is', 'an', 'example'])"]},{"cell_type":"markdown","metadata":{},"source":["#### Working as intended!"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:24:25.621765Z","iopub.status.busy":"2023-03-20T10:24:25.621290Z","iopub.status.idle":"2023-03-20T10:24:25.627593Z","shell.execute_reply":"2023-03-20T10:24:25.626254Z","shell.execute_reply.started":"2023-03-20T10:24:25.621723Z"},"trusted":true},"outputs":[],"source":["text_pipeline = lambda x: vocab(tokenizer(x))\n","label_pipeline = lambda x: int(x) "]},{"cell_type":"markdown","metadata":{},"source":["## Custom DataLoader"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:24:26.209220Z","iopub.status.busy":"2023-03-20T10:24:26.208803Z","iopub.status.idle":"2023-03-20T10:24:26.215063Z","shell.execute_reply":"2023-03-20T10:24:26.213766Z","shell.execute_reply.started":"2023-03-20T10:24:26.209184Z"},"trusted":true},"outputs":[],"source":["train_dataset_custom = CustomDataset(train_df)\n","val_dataset_custom = CustomDataset(val_df)\n","test_dataset_custom = CustomDataset(test_df)"]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:25:42.175756Z","iopub.status.busy":"2023-03-20T10:25:42.175279Z","iopub.status.idle":"2023-03-20T10:25:42.185956Z","shell.execute_reply":"2023-03-20T10:25:42.184707Z","shell.execute_reply.started":"2023-03-20T10:25:42.175714Z"},"trusted":true},"outputs":[],"source":["def collate_batch(batch):\n","    label_list, text_list, offsets = [], [], [0]\n","    for (_label, _text) in batch:\n","        label_list.append(label_pipeline(_label))\n","        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n","        text_list.append(processed_text)\n","        offsets.append(processed_text.size(0))\n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","    text_list = torch.cat(text_list)\n","    return label_list.to(device), text_list.to(device), offsets.to(device)\n","\n","train_dataloader = DataLoader(train_dataset_custom, batch_size=8, shuffle=True, collate_fn=collate_batch)\n","val_dataloader = DataLoader(val_dataset_custom, batch_size=8, shuffle=False, collate_fn=collate_batch)\n","test_dataloader = DataLoader(test_dataset_custom, batch_size=1, shuffle=False, collate_fn=collate_batch)"]},{"cell_type":"markdown","metadata":{},"source":["#### Before sending the data to our model, collate_fn function works on a batch of samples generated from DataLoader.\n","#### The offset is a tensor of delimiters to represent the beginning index of the individual sequence in the text tensor. \n","#### Label is a tensor saving the labels of individual text entries.\n","#### Read more about it [here](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html)."]},{"cell_type":"markdown","metadata":{},"source":["# Modeling"]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:24:36.306463Z","iopub.status.busy":"2023-03-20T10:24:36.306022Z","iopub.status.idle":"2023-03-20T10:24:36.315471Z","shell.execute_reply":"2023-03-20T10:24:36.314217Z","shell.execute_reply.started":"2023-03-20T10:24:36.306420Z"},"trusted":true},"outputs":[],"source":["class TextClassificationModel(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_dim, num_class):\n","        super(TextClassificationModel, self).__init__()\n","        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n","        self.fc = nn.Linear(embed_dim, num_class)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        initrange = 0.5\n","        self.embedding.weight.data.uniform_(-initrange, initrange)\n","        self.fc.weight.data.uniform_(-initrange, initrange)\n","        self.fc.bias.data.zero_()\n","\n","    def forward(self, text, offsets):\n","        embedded = self.embedding(text, offsets)\n","        return self.fc(embedded)"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:24:40.295985Z","iopub.status.busy":"2023-03-20T10:24:40.295608Z","iopub.status.idle":"2023-03-20T10:24:40.324282Z","shell.execute_reply":"2023-03-20T10:24:40.322993Z","shell.execute_reply.started":"2023-03-20T10:24:40.295952Z"},"trusted":true},"outputs":[],"source":["num_class = 2\n","vocab_size = len(vocab)\n","emsize = 64\n","model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:26:37.959110Z","iopub.status.busy":"2023-03-20T10:26:37.958723Z","iopub.status.idle":"2023-03-20T10:26:37.972655Z","shell.execute_reply":"2023-03-20T10:26:37.971113Z","shell.execute_reply.started":"2023-03-20T10:26:37.959077Z"},"trusted":true},"outputs":[],"source":["def train(dataloader):\n","    model.train()\n","    total_acc, total_count = 0, 0\n","    log_interval = 500\n","    start_time = time.time()\n","\n","    for idx, (label, text, offsets) in enumerate(dataloader):\n","        optimizer.zero_grad()\n","        predicted_label = model(text, offsets)\n","        loss = criterion(predicted_label, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","        optimizer.step()\n","        total_acc += (predicted_label.argmax(1) == label).sum().item()\n","        total_count += label.size(0)\n","        if idx % log_interval == 0 and idx > 0:\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:5d}/{:5d} batches '\n","                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n","                                              total_acc/total_count))\n","            total_acc, total_count = 0, 0\n","            start_time = time.time()\n","\n","def evaluate(dataloader):\n","    model.eval()\n","    total_acc, total_count = 0, 0\n","\n","    with torch.no_grad():\n","        for idx, (label, text, offsets) in enumerate(dataloader):\n","            predicted_label = model(text, offsets)\n","            loss = criterion(predicted_label, label)\n","            total_acc += (predicted_label.argmax(1) == label).sum().item()\n","            total_count += label.size(0)\n","    return total_acc/total_count\n","\n","def submission(dataloader): # Code for submission\n","    preds = []\n","    model.eval()\n","    total_acc, total_count = 0, 0\n","\n","    with torch.no_grad():\n","        for idx, (label, text, offsets) in enumerate(dataloader):\n","            predicted_label = model(text, offsets)\n","            preds.append(predicted_label.argmax(1).item())\n","            \n","    return preds"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:24:41.101725Z","iopub.status.busy":"2023-03-20T10:24:41.101318Z","iopub.status.idle":"2023-03-20T10:25:07.812800Z","shell.execute_reply":"2023-03-20T10:25:07.811389Z","shell.execute_reply.started":"2023-03-20T10:24:41.101689Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["| epoch   1 |   500/  762 batches | accuracy    0.653\n","-----------------------------------------------------------\n","| end of epoch   1 | time:  2.72s | valid accuracy    0.731 \n","-----------------------------------------------------------\n","\n","\n","| epoch   2 |   500/  762 batches | accuracy    0.784\n","-----------------------------------------------------------\n","| end of epoch   2 | time:  2.59s | valid accuracy    0.760 \n","-----------------------------------------------------------\n","\n","\n","| epoch   3 |   500/  762 batches | accuracy    0.827\n","-----------------------------------------------------------\n","| end of epoch   3 | time:  2.78s | valid accuracy    0.787 \n","-----------------------------------------------------------\n","\n","\n","| epoch   4 |   500/  762 batches | accuracy    0.861\n","-----------------------------------------------------------\n","| end of epoch   4 | time:  2.68s | valid accuracy    0.749 \n","-----------------------------------------------------------\n","\n","\n","| epoch   5 |   500/  762 batches | accuracy    0.905\n","-----------------------------------------------------------\n","| end of epoch   5 | time:  2.65s | valid accuracy    0.787 \n","-----------------------------------------------------------\n","\n","\n","| epoch   6 |   500/  762 batches | accuracy    0.917\n","-----------------------------------------------------------\n","| end of epoch   6 | time:  2.51s | valid accuracy    0.791 \n","-----------------------------------------------------------\n","\n","\n","| epoch   7 |   500/  762 batches | accuracy    0.924\n","-----------------------------------------------------------\n","| end of epoch   7 | time:  2.68s | valid accuracy    0.793 \n","-----------------------------------------------------------\n","\n","\n","| epoch   8 |   500/  762 batches | accuracy    0.928\n","-----------------------------------------------------------\n","| end of epoch   8 | time:  2.74s | valid accuracy    0.791 \n","-----------------------------------------------------------\n","\n","\n","| epoch   9 |   500/  762 batches | accuracy    0.931\n","-----------------------------------------------------------\n","| end of epoch   9 | time:  2.66s | valid accuracy    0.789 \n","-----------------------------------------------------------\n","\n","\n","| epoch  10 |   500/  762 batches | accuracy    0.932\n","-----------------------------------------------------------\n","| end of epoch  10 | time:  2.67s | valid accuracy    0.789 \n","-----------------------------------------------------------\n","\n","\n"]}],"source":["EPOCHS = 10\n","LR = 5\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n","total_accu = None\n","\n","for epoch in range(1, EPOCHS + 1):\n","    epoch_start_time = time.time()\n","    train(train_dataloader)\n","    accu_val = evaluate(val_dataloader)\n","    if total_accu is not None and total_accu > accu_val:\n","        scheduler.step()\n","    else:\n","        total_accu = accu_val\n","    print('-' * 59)\n","    print('| end of epoch {:3d} | time: {:5.2f}s | '\n","          'valid accuracy {:8.3f} '.format(epoch,\n","                                           time.time() - epoch_start_time,\n","                                           accu_val))\n","    print('-' * 59)\n","    print(\"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":115,"metadata":{"execution":{"iopub.execute_input":"2023-03-20T10:27:23.114014Z","iopub.status.busy":"2023-03-20T10:27:23.113594Z","iopub.status.idle":"2023-03-20T10:27:24.049471Z","shell.execute_reply":"2023-03-20T10:27:24.048485Z","shell.execute_reply.started":"2023-03-20T10:27:23.113975Z"},"trusted":true},"outputs":[],"source":["preds = submission(test_dataloader)\n","\n","sample['target'] = preds\n","\n","sample.to_csv('submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.11.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":4}
